{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "space_craft.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkxgYWASDAGz"
      },
      "source": [
        "# Modified Squeezenet\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7XIFwbQ6qsb",
        "outputId": "b9ad74bc-a236-40e4-fddf-404b73d8f227"
      },
      "source": [
        "!pip install pipreqs"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pipreqs\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/83/b1560948400a07ec094a15c2f64587b70e1a5ab5f7b375ba902fcab5b6c3/pipreqs-0.4.10-py2.py3-none-any.whl\n",
            "Collecting yarg\n",
            "  Downloading https://files.pythonhosted.org/packages/8b/90/89a2ff242ccab6a24fbab18dbbabc67c51a6f0ed01f9a0f41689dc177419/yarg-0.1.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from pipreqs) (0.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from yarg->pipreqs) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->yarg->pipreqs) (2.10)\n",
            "Installing collected packages: yarg, pipreqs\n",
            "Successfully installed pipreqs-0.4.10 yarg-0.1.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYXGfM4O6uNV"
      },
      "source": [
        "!pip freeze -> requirements.txt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyCQnnApDHyw",
        "outputId": "75b19e22-28f6-41e8-96ce-00ac703588a8"
      },
      "source": [
        "#fixed version of tqdm output for Colab\r\n",
        "!pip install --force https://github.com/chengs/tqdm/archive/colab.zip\r\n",
        "#IGNORE restart runtime warning, it is indeed installed\r\n",
        "#missing a few extra packages that we will need later! \r\n",
        "!pip install efficientnet_pytorch\r\n",
        "!pip install tensorboardX"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/chengs/tqdm/archive/colab.zip\n",
            "\u001b[?25l  Downloading https://github.com/chengs/tqdm/archive/colab.zip\n",
            "\u001b[K     - 256kB 12.5MB/s\n",
            "\u001b[?25hBuilding wheels for collected packages: tqdm\n",
            "  Building wheel for tqdm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tqdm: filename=tqdm-4.28.1-py2.py3-none-any.whl size=47868 sha256=d5978afe2040651a0da1af85a7eec514c4a26ce4ae50bd58a897b3b2be057ad7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vo125x2k/wheels/41/18/ee/d5dd158441b27965855b1bbae03fa2d8a91fe645c01b419896\n",
            "Successfully built tqdm\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.28.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.28.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tqdm\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "Successfully installed tqdm-4.28.1\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/83/f9c5f44060f996279e474185ebcbd8dbd91179593bffb9abe3afa55d085b/efficientnet_pytorch-0.7.0.tar.gz\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.7.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (1.19.5)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-cp37-none-any.whl size=16031 sha256=d0ae360a107f4e0f6673f0f101dbb62b69579c668bfabc6c34866c390f0b5e45\n",
            "  Stored in directory: /root/.cache/pip/wheels/e9/c6/e1/7a808b26406239712cfce4b5ceeb67d9513ae32aa4b31445c6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.0\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (54.0.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxKJa0ytbKcH",
        "outputId": "21836f9d-b566-4a13-c3b1-734a32118f79"
      },
      "source": [
        "!git clone https://github.com/myproject-01/space.git"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'space'...\n",
            "remote: Enumerating objects: 157, done.\u001b[K\n",
            "remote: Counting objects: 100% (157/157), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 157 (delta 89), reused 157 (delta 89), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (157/157), 569.04 KiB | 21.08 MiB/s, done.\n",
            "Resolving deltas: 100% (89/89), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knnFbw4d9qtd"
      },
      "source": [
        "# DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaDJldHu9cQ3"
      },
      "source": [
        "import os\r\n",
        "import torch\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from pycocotools.coco import COCO\r\n",
        "import cv2\r\n",
        "\r\n",
        "\r\n",
        "class CocoDataset(Dataset):\r\n",
        "    def __init__(self, root_dir, img_dir=\"images\", set_dir='train2017', transform=None):\r\n",
        "\r\n",
        "        self.root_dir = root_dir\r\n",
        "        self.img_dir = img_dir\r\n",
        "        self.set_name = set_dir\r\n",
        "        self.transform = transform\r\n",
        "\r\n",
        "        self.coco = COCO(os.path.join(self.root_dir, 'annotations', 'instances_' + self.set_name + '.json'))\r\n",
        "        self.image_ids = self.coco.getImgIds()\r\n",
        "\r\n",
        "        self.load_classes()\r\n",
        "\r\n",
        "    def load_classes(self):\r\n",
        "\r\n",
        "        # load class names (name -> label)\r\n",
        "        categories = self.coco.loadCats(self.coco.getCatIds())\r\n",
        "        categories.sort(key=lambda x: x['id'])\r\n",
        "\r\n",
        "        self.classes = {}\r\n",
        "        self.coco_labels = {}\r\n",
        "        self.coco_labels_inverse = {}\r\n",
        "        for c in categories:\r\n",
        "            self.coco_labels[len(self.classes)] = c['id']\r\n",
        "            self.coco_labels_inverse[c['id']] = len(self.classes)\r\n",
        "            self.classes[c['name']] = len(self.classes)\r\n",
        "\r\n",
        "        # also load the reverse (label -> name)\r\n",
        "        self.labels = {}\r\n",
        "        for key, value in self.classes.items():\r\n",
        "            self.labels[value] = key\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.image_ids)\r\n",
        "\r\n",
        "    def __getitem__(self, idx):\r\n",
        "\r\n",
        "        img = self.load_image(idx)\r\n",
        "        annot = self.load_annotations(idx)\r\n",
        "        sample = {'img': img, 'annot': annot}\r\n",
        "        if self.transform:\r\n",
        "            sample = self.transform(sample)\r\n",
        "        return sample\r\n",
        "\r\n",
        "    def load_image(self, image_index):\r\n",
        "        image_info = self.coco.loadImgs(self.image_ids[image_index])[0]\r\n",
        "        path = os.path.join(self.root_dir, self.img_dir, self.set_name, image_info['file_name'])\r\n",
        "        img = cv2.imread(path)\r\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
        "\r\n",
        "        # if len(img.shape) == 2:\r\n",
        "        #     img = skimage.color.gray2rgb(img)\r\n",
        "\r\n",
        "        return img.astype(np.float32) / 255.\r\n",
        "\r\n",
        "    def load_annotations(self, image_index):\r\n",
        "        # get ground truth annotations\r\n",
        "        annotations_ids = self.coco.getAnnIds(imgIds=self.image_ids[image_index], iscrowd=False)\r\n",
        "        annotations = np.zeros((0, 5))\r\n",
        "\r\n",
        "        # some images appear to miss annotations\r\n",
        "        if len(annotations_ids) == 0:\r\n",
        "            return annotations\r\n",
        "\r\n",
        "        # parse annotations\r\n",
        "        coco_annotations = self.coco.loadAnns(annotations_ids)\r\n",
        "        for idx, a in enumerate(coco_annotations):\r\n",
        "\r\n",
        "            # some annotations have basically no width / height, skip them\r\n",
        "            if a['area'] == 0:\r\n",
        "                continue\r\n",
        "            \r\n",
        "            if a['bbox'][2] < 1 or a['bbox'][3] < 1:\r\n",
        "                continue\r\n",
        "\r\n",
        "            annotation = np.zeros((1, 5))\r\n",
        "            annotation[0, :4] = a['bbox']\r\n",
        "            annotation[0, 4] = self.coco_label_to_label(a['category_id'])\r\n",
        "            annotations = np.append(annotations, annotation, axis=0)\r\n",
        "\r\n",
        "        # transform from [x, y, w, h] to [x1, y1, x2, y2]\r\n",
        "        annotations[:, 2] = annotations[:, 0] + annotations[:, 2]\r\n",
        "        annotations[:, 3] = annotations[:, 1] + annotations[:, 3]\r\n",
        "\r\n",
        "        return annotations\r\n",
        "\r\n",
        "    def coco_label_to_label(self, coco_label):\r\n",
        "        return self.coco_labels_inverse[coco_label]\r\n",
        "\r\n",
        "    def label_to_coco_label(self, label):\r\n",
        "        return self.coco_labels[label]\r\n",
        "\r\n",
        "    def num_classes(self):\r\n",
        "        return len(self.classes)\r\n",
        "\r\n",
        "\r\n",
        "def collater(data):\r\n",
        "    imgs = [s['img'] for s in data]\r\n",
        "    annots = [s['annot'] for s in data]\r\n",
        "    scales = [s['scale'] for s in data]\r\n",
        "\r\n",
        "    imgs = torch.from_numpy(np.stack(imgs, axis=0))\r\n",
        "\r\n",
        "    max_num_annots = max(annot.shape[0] for annot in annots)\r\n",
        "\r\n",
        "    if max_num_annots > 0:\r\n",
        "\r\n",
        "        annot_padded = torch.ones((len(annots), max_num_annots, 5)) * -1\r\n",
        "\r\n",
        "        if max_num_annots > 0:\r\n",
        "            for idx, annot in enumerate(annots):\r\n",
        "                if annot.shape[0] > 0:\r\n",
        "                    annot_padded[idx, :annot.shape[0], :] = annot\r\n",
        "    else:\r\n",
        "        annot_padded = torch.ones((len(annots), 1, 5)) * -1\r\n",
        "\r\n",
        "    imgs = imgs.permute(0, 3, 1, 2)\r\n",
        "\r\n",
        "    return {'img': imgs, 'annot': annot_padded, 'scale': scales}\r\n",
        "\r\n",
        "\r\n",
        "class Resizer(object):\r\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\r\n",
        "\r\n",
        "    def __call__(self, sample, common_size=512):\r\n",
        "        image, annots = sample['img'], sample['annot']\r\n",
        "        height, width, _ = image.shape\r\n",
        "        if height > width:\r\n",
        "            scale = common_size / height\r\n",
        "            resized_height = common_size\r\n",
        "            resized_width = int(width * scale)\r\n",
        "        else:\r\n",
        "            scale = common_size / width\r\n",
        "            resized_height = int(height * scale)\r\n",
        "            resized_width = common_size\r\n",
        "\r\n",
        "        image = cv2.resize(image, (resized_width, resized_height))\r\n",
        "\r\n",
        "        new_image = np.zeros((common_size, common_size, 3))\r\n",
        "        new_image[0:resized_height, 0:resized_width] = image\r\n",
        "\r\n",
        "        annots[:, :4] *= scale\r\n",
        "\r\n",
        "        return {'img': torch.from_numpy(new_image), 'annot': torch.from_numpy(annots), 'scale': scale}\r\n",
        "\r\n",
        "\r\n",
        "class Augmenter(object):\r\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\r\n",
        "\r\n",
        "    def __call__(self, sample, flip_x=0.5):\r\n",
        "        if np.random.rand() < flip_x:\r\n",
        "            image, annots = sample['img'], sample['annot']\r\n",
        "            image = image[:, ::-1, :]\r\n",
        "\r\n",
        "            rows, cols, channels = image.shape\r\n",
        "\r\n",
        "            x1 = annots[:, 0].copy()\r\n",
        "            x2 = annots[:, 2].copy()\r\n",
        "\r\n",
        "            x_tmp = x1.copy()\r\n",
        "\r\n",
        "            annots[:, 0] = cols - x2\r\n",
        "            annots[:, 2] = cols - x_tmp\r\n",
        "\r\n",
        "            sample = {'img': image, 'annot': annots}\r\n",
        "\r\n",
        "        return sample\r\n",
        "\r\n",
        "\r\n",
        "class Normalizer(object):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        self.mean = np.array([[[0.485, 0.456, 0.406]]])\r\n",
        "        self.std = np.array([[[0.229, 0.224, 0.225]]])\r\n",
        "\r\n",
        "    def __call__(self, sample):\r\n",
        "        image, annots = sample['img'], sample['annot']\r\n",
        "\r\n",
        "        return {'img': ((image.astype(np.float32) - self.mean) / self.std), 'annot': annots}\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vnEWZ2y9vVc"
      },
      "source": [
        "# UTILS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFkmngIC9xge"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "class BBoxTransform(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, mean=None, std=None):\r\n",
        "        super(BBoxTransform, self).__init__()\r\n",
        "        if mean is None:\r\n",
        "            self.mean = torch.from_numpy(np.array([0, 0, 0, 0]).astype(np.float32))\r\n",
        "        else:\r\n",
        "            self.mean = mean\r\n",
        "        if std is None:\r\n",
        "            self.std = torch.from_numpy(np.array([0.1, 0.1, 0.2, 0.2]).astype(np.float32))\r\n",
        "        else:\r\n",
        "            self.std = std\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            self.mean = self.mean.cuda()\r\n",
        "            self.std = self.std.cuda()\r\n",
        "\r\n",
        "    def forward(self, boxes, deltas):\r\n",
        "\r\n",
        "        widths = boxes[:, :, 2] - boxes[:, :, 0]\r\n",
        "        heights = boxes[:, :, 3] - boxes[:, :, 1]\r\n",
        "        ctr_x = boxes[:, :, 0] + 0.5 * widths\r\n",
        "        ctr_y = boxes[:, :, 1] + 0.5 * heights\r\n",
        "\r\n",
        "        dx = deltas[:, :, 0] * self.std[0] + self.mean[0]\r\n",
        "        dy = deltas[:, :, 1] * self.std[1] + self.mean[1]\r\n",
        "        dw = deltas[:, :, 2] * self.std[2] + self.mean[2]\r\n",
        "        dh = deltas[:, :, 3] * self.std[3] + self.mean[3]\r\n",
        "\r\n",
        "        pred_ctr_x = ctr_x + dx * widths\r\n",
        "        pred_ctr_y = ctr_y + dy * heights\r\n",
        "        pred_w = torch.exp(dw) * widths\r\n",
        "        pred_h = torch.exp(dh) * heights\r\n",
        "\r\n",
        "        pred_boxes_x1 = pred_ctr_x - 0.5 * pred_w\r\n",
        "        pred_boxes_y1 = pred_ctr_y - 0.5 * pred_h\r\n",
        "        pred_boxes_x2 = pred_ctr_x + 0.5 * pred_w\r\n",
        "        pred_boxes_y2 = pred_ctr_y + 0.5 * pred_h\r\n",
        "\r\n",
        "        pred_boxes = torch.stack([pred_boxes_x1, pred_boxes_y1, pred_boxes_x2, pred_boxes_y2], dim=2)\r\n",
        "\r\n",
        "        return pred_boxes\r\n",
        "\r\n",
        "\r\n",
        "class ClipBoxes(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(ClipBoxes, self).__init__()\r\n",
        "\r\n",
        "    def forward(self, boxes, img):\r\n",
        "        batch_size, num_channels, height, width = img.shape\r\n",
        "\r\n",
        "        boxes[:, :, 0] = torch.clamp(boxes[:, :, 0], min=0)\r\n",
        "        boxes[:, :, 1] = torch.clamp(boxes[:, :, 1], min=0)\r\n",
        "\r\n",
        "        boxes[:, :, 2] = torch.clamp(boxes[:, :, 2], max=width)\r\n",
        "        boxes[:, :, 3] = torch.clamp(boxes[:, :, 3], max=height)\r\n",
        "\r\n",
        "        return boxes\r\n",
        "\r\n",
        "\r\n",
        "class Anchors(nn.Module):\r\n",
        "    def __init__(self, pyramid_levels=None, strides=None, sizes=None, ratios=None, scales=None):\r\n",
        "        super(Anchors, self).__init__()\r\n",
        "\r\n",
        "        if pyramid_levels is None:\r\n",
        "            self.pyramid_levels = [3, 4, 5, 6, 7]\r\n",
        "        if strides is None:\r\n",
        "            self.strides = [2 ** x for x in self.pyramid_levels]\r\n",
        "        if sizes is None:\r\n",
        "            self.sizes = [2 ** (x + 2) for x in self.pyramid_levels]\r\n",
        "        if ratios is None:\r\n",
        "            self.ratios = np.array([0.5, 1, 2])\r\n",
        "        if scales is None:\r\n",
        "            self.scales = np.array([2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])\r\n",
        "\r\n",
        "    def forward(self, image):\r\n",
        "\r\n",
        "        image_shape = image.shape[2:]\r\n",
        "        image_shape = np.array(image_shape)\r\n",
        "        image_shapes = [(image_shape + 2 ** x - 1) // (2 ** x) for x in self.pyramid_levels]\r\n",
        "\r\n",
        "        all_anchors = np.zeros((0, 4)).astype(np.float32)\r\n",
        "\r\n",
        "        for idx, p in enumerate(self.pyramid_levels):\r\n",
        "            anchors = generate_anchors(base_size=self.sizes[idx], ratios=self.ratios, scales=self.scales)\r\n",
        "            shifted_anchors = shift(image_shapes[idx], self.strides[idx], anchors)\r\n",
        "            all_anchors = np.append(all_anchors, shifted_anchors, axis=0)\r\n",
        "\r\n",
        "        all_anchors = np.expand_dims(all_anchors, axis=0)\r\n",
        "\r\n",
        "        anchors = torch.from_numpy(all_anchors.astype(np.float32))\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            anchors = anchors.cuda()\r\n",
        "        return anchors\r\n",
        "\r\n",
        "\r\n",
        "def generate_anchors(base_size=16, ratios=None, scales=None):\r\n",
        "    if ratios is None:\r\n",
        "        ratios = np.array([0.5, 1, 2])\r\n",
        "\r\n",
        "    if scales is None:\r\n",
        "        scales = np.array([2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)])\r\n",
        "\r\n",
        "    num_anchors = len(ratios) * len(scales)\r\n",
        "    anchors = np.zeros((num_anchors, 4))\r\n",
        "    anchors[:, 2:] = base_size * np.tile(scales, (2, len(ratios))).T\r\n",
        "    areas = anchors[:, 2] * anchors[:, 3]\r\n",
        "    anchors[:, 2] = np.sqrt(areas / np.repeat(ratios, len(scales)))\r\n",
        "    anchors[:, 3] = anchors[:, 2] * np.repeat(ratios, len(scales))\r\n",
        "    anchors[:, 0::2] -= np.tile(anchors[:, 2] * 0.5, (2, 1)).T\r\n",
        "    anchors[:, 1::2] -= np.tile(anchors[:, 3] * 0.5, (2, 1)).T\r\n",
        "\r\n",
        "    return anchors\r\n",
        "\r\n",
        "\r\n",
        "def compute_shape(image_shape, pyramid_levels):\r\n",
        "    image_shape = np.array(image_shape[:2])\r\n",
        "    image_shapes = [(image_shape + 2 ** x - 1) // (2 ** x) for x in pyramid_levels]\r\n",
        "    return image_shapes\r\n",
        "\r\n",
        "\r\n",
        "def shift(shape, stride, anchors):\r\n",
        "    shift_x = (np.arange(0, shape[1]) + 0.5) * stride\r\n",
        "    shift_y = (np.arange(0, shape[0]) + 0.5) * stride\r\n",
        "    shift_x, shift_y = np.meshgrid(shift_x, shift_y)\r\n",
        "    shifts = np.vstack((\r\n",
        "        shift_x.ravel(), shift_y.ravel(),\r\n",
        "        shift_x.ravel(), shift_y.ravel()\r\n",
        "    )).transpose()\r\n",
        "\r\n",
        "    A = anchors.shape[0]\r\n",
        "    K = shifts.shape[0]\r\n",
        "    all_anchors = (anchors.reshape((1, A, 4)) + shifts.reshape((1, K, 4)).transpose((1, 0, 2)))\r\n",
        "    all_anchors = all_anchors.reshape((K * A, 4))\r\n",
        "\r\n",
        "    return all_anchors\r\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7guXUDr9vYN"
      },
      "source": [
        "# LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH8Nvk1R-A1p"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "\r\n",
        "\r\n",
        "def calc_iou(a, b):\r\n",
        "\r\n",
        "    area = (b[:, 2] - b[:, 0]) * (b[:, 3] - b[:, 1])\r\n",
        "    iw = torch.min(torch.unsqueeze(a[:, 2], dim=1), b[:, 2]) - torch.max(torch.unsqueeze(a[:, 0], 1), b[:, 0])\r\n",
        "    ih = torch.min(torch.unsqueeze(a[:, 3], dim=1), b[:, 3]) - torch.max(torch.unsqueeze(a[:, 1], 1), b[:, 1])\r\n",
        "    iw = torch.clamp(iw, min=0)\r\n",
        "    ih = torch.clamp(ih, min=0)\r\n",
        "    ua = torch.unsqueeze((a[:, 2] - a[:, 0]) * (a[:, 3] - a[:, 1]), dim=1) + area - iw * ih\r\n",
        "    ua = torch.clamp(ua, min=1e-8)\r\n",
        "    intersection = iw * ih\r\n",
        "    IoU = intersection / ua\r\n",
        "\r\n",
        "    return IoU\r\n",
        "\r\n",
        "\r\n",
        "class FocalLoss(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(FocalLoss, self).__init__()\r\n",
        "\r\n",
        "    def forward(self, classifications, regressions, anchors, annotations):\r\n",
        "        alpha = 0.25\r\n",
        "        gamma = 2.0\r\n",
        "        batch_size = classifications.shape[0]\r\n",
        "        classification_losses = []\r\n",
        "        regression_losses = []\r\n",
        "\r\n",
        "        anchor = anchors[0, :, :]\r\n",
        "\r\n",
        "        anchor_widths = anchor[:, 2] - anchor[:, 0]\r\n",
        "        anchor_heights = anchor[:, 3] - anchor[:, 1]\r\n",
        "        anchor_ctr_x = anchor[:, 0] + 0.5 * anchor_widths\r\n",
        "        anchor_ctr_y = anchor[:, 1] + 0.5 * anchor_heights\r\n",
        "\r\n",
        "        for j in range(batch_size):\r\n",
        "\r\n",
        "            classification = classifications[j, :, :]\r\n",
        "            regression = regressions[j, :, :]\r\n",
        "\r\n",
        "            bbox_annotation = annotations[j, :, :]\r\n",
        "            bbox_annotation = bbox_annotation[bbox_annotation[:, 4] != -1]\r\n",
        "\r\n",
        "            if bbox_annotation.shape[0] == 0:\r\n",
        "                if torch.cuda.is_available():\r\n",
        "                    regression_losses.append(torch.tensor(0).float().cuda())\r\n",
        "                    classification_losses.append(torch.tensor(0).float().cuda())\r\n",
        "                else:\r\n",
        "                    regression_losses.append(torch.tensor(0).float())\r\n",
        "                    classification_losses.append(torch.tensor(0).float())\r\n",
        "\r\n",
        "                continue\r\n",
        "\r\n",
        "            classification = torch.clamp(classification, 1e-4, 1.0 - 1e-4)\r\n",
        "\r\n",
        "            IoU = calc_iou(anchors[0, :, :], bbox_annotation[:, :4])\r\n",
        "\r\n",
        "            IoU_max, IoU_argmax = torch.max(IoU, dim=1)\r\n",
        "\r\n",
        "            # compute the loss for classification\r\n",
        "            targets = torch.ones(classification.shape) * -1\r\n",
        "            if torch.cuda.is_available():\r\n",
        "                targets = targets.cuda()\r\n",
        "\r\n",
        "            targets[torch.lt(IoU_max, 0.4), :] = 0\r\n",
        "\r\n",
        "            positive_indices = torch.ge(IoU_max, 0.5)\r\n",
        "\r\n",
        "            num_positive_anchors = positive_indices.sum()\r\n",
        "\r\n",
        "            assigned_annotations = bbox_annotation[IoU_argmax, :]\r\n",
        "\r\n",
        "            targets[positive_indices, :] = 0\r\n",
        "            targets[positive_indices, assigned_annotations[positive_indices, 4].long()] = 1\r\n",
        "\r\n",
        "            alpha_factor = torch.ones(targets.shape) * alpha\r\n",
        "            if torch.cuda.is_available():\r\n",
        "                alpha_factor = alpha_factor.cuda()\r\n",
        "\r\n",
        "            alpha_factor = torch.where(torch.eq(targets, 1.), alpha_factor, 1. - alpha_factor)\r\n",
        "            focal_weight = torch.where(torch.eq(targets, 1.), 1. - classification, classification)\r\n",
        "            focal_weight = alpha_factor * torch.pow(focal_weight, gamma)\r\n",
        "\r\n",
        "            bce = -(targets * torch.log(classification) + (1.0 - targets) * torch.log(1.0 - classification))\r\n",
        "\r\n",
        "            cls_loss = focal_weight * bce\r\n",
        "\r\n",
        "            zeros = torch.zeros(cls_loss.shape)\r\n",
        "            if torch.cuda.is_available():\r\n",
        "                zeros = zeros.cuda()\r\n",
        "            cls_loss = torch.where(torch.ne(targets, -1.0), cls_loss, zeros)\r\n",
        "\r\n",
        "            classification_losses.append(cls_loss.sum() / torch.clamp(num_positive_anchors.float(), min=1.0))\r\n",
        "\r\n",
        "\r\n",
        "            if positive_indices.sum() > 0:\r\n",
        "                assigned_annotations = assigned_annotations[positive_indices, :]\r\n",
        "\r\n",
        "                anchor_widths_pi = anchor_widths[positive_indices]\r\n",
        "                anchor_heights_pi = anchor_heights[positive_indices]\r\n",
        "                anchor_ctr_x_pi = anchor_ctr_x[positive_indices]\r\n",
        "                anchor_ctr_y_pi = anchor_ctr_y[positive_indices]\r\n",
        "\r\n",
        "                gt_widths = assigned_annotations[:, 2] - assigned_annotations[:, 0]\r\n",
        "                gt_heights = assigned_annotations[:, 3] - assigned_annotations[:, 1]\r\n",
        "                gt_ctr_x = assigned_annotations[:, 0] + 0.5 * gt_widths\r\n",
        "                gt_ctr_y = assigned_annotations[:, 1] + 0.5 * gt_heights\r\n",
        "\r\n",
        "                gt_widths = torch.clamp(gt_widths, min=1)\r\n",
        "                gt_heights = torch.clamp(gt_heights, min=1)\r\n",
        "\r\n",
        "                targets_dx = (gt_ctr_x - anchor_ctr_x_pi) / anchor_widths_pi\r\n",
        "                targets_dy = (gt_ctr_y - anchor_ctr_y_pi) / anchor_heights_pi\r\n",
        "                targets_dw = torch.log(gt_widths / anchor_widths_pi)\r\n",
        "                targets_dh = torch.log(gt_heights / anchor_heights_pi)\r\n",
        "\r\n",
        "                targets = torch.stack((targets_dx, targets_dy, targets_dw, targets_dh))\r\n",
        "                targets = targets.t()\r\n",
        "\r\n",
        "                norm = torch.Tensor([[0.1, 0.1, 0.2, 0.2]])\r\n",
        "                if torch.cuda.is_available():\r\n",
        "                    norm = norm.cuda()\r\n",
        "                targets = targets / norm\r\n",
        "\r\n",
        "                regression_diff = torch.abs(targets - regression[positive_indices, :])\r\n",
        "\r\n",
        "                regression_loss = torch.where(\r\n",
        "                    torch.le(regression_diff, 1.0 / 9.0),\r\n",
        "                    0.5 * 9.0 * torch.pow(regression_diff, 2),\r\n",
        "                    regression_diff - 0.5 / 9.0\r\n",
        "                )\r\n",
        "                regression_losses.append(regression_loss.mean())\r\n",
        "            else:\r\n",
        "                if torch.cuda.is_available():\r\n",
        "                    regression_losses.append(torch.tensor(0).float().cuda())\r\n",
        "                else:\r\n",
        "                    regression_losses.append(torch.tensor(0).float())\r\n",
        "\r\n",
        "        return torch.stack(classification_losses).mean(dim=0, keepdim=True), torch.stack(regression_losses).mean(dim=0,\r\n",
        "                                                                                                                 keepdim=True)\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjE42sxV-F68"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "Zp_9y7BH-L5Z",
        "outputId": "8a3810f3-bd03-4e8f-b7da-2052d6d19839"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "import torch\r\n",
        "import math\r\n",
        "from efficientnet_pytorch import EfficientNet as EffNet\r\n",
        "from torchvision.ops.boxes import nms as nms_torch\r\n",
        "\r\n",
        "\r\n",
        "def nms(dets, thresh):\r\n",
        "    return nms_torch(dets[:, :4], dets[:, 4], thresh)\r\n",
        "\r\n",
        "\r\n",
        "class ConvBlock(nn.Module):\r\n",
        "    def __init__(self, num_channels):\r\n",
        "        super(ConvBlock, self).__init__()\r\n",
        "        self.conv = nn.Sequential(\r\n",
        "            nn.Conv2d(num_channels, num_channels, kernel_size=3, stride=1, padding=1, groups=num_channels),\r\n",
        "            nn.Conv2d(num_channels, num_channels, kernel_size=1, stride=1, padding=0),\r\n",
        "            nn.BatchNorm2d(num_features=num_channels, momentum=0.9997, eps=4e-5), nn.ReLU())\r\n",
        "\r\n",
        "    def forward(self, input):\r\n",
        "        return self.conv(input)\r\n",
        "\r\n",
        "\r\n",
        "class BiFPN(nn.Module):\r\n",
        "    def __init__(self, num_channels, epsilon=1e-4):\r\n",
        "        super(BiFPN, self).__init__()\r\n",
        "        self.epsilon = epsilon\r\n",
        "        # Conv layers\r\n",
        "        self.conv6_up = ConvBlock(num_channels)\r\n",
        "        self.conv5_up = ConvBlock(num_channels)\r\n",
        "        self.conv4_up = ConvBlock(num_channels)\r\n",
        "        self.conv3_up = ConvBlock(num_channels)\r\n",
        "        self.conv4_down = ConvBlock(num_channels)\r\n",
        "        self.conv5_down = ConvBlock(num_channels)\r\n",
        "        self.conv6_down = ConvBlock(num_channels)\r\n",
        "        self.conv7_down = ConvBlock(num_channels)\r\n",
        "\r\n",
        "        # Feature scaling layers\r\n",
        "        self.p6_upsample = nn.Upsample(scale_factor=2, mode='nearest')\r\n",
        "        self.p5_upsample = nn.Upsample(scale_factor=2, mode='nearest')\r\n",
        "        self.p4_upsample = nn.Upsample(scale_factor=2, mode='nearest')\r\n",
        "        self.p3_upsample = nn.Upsample(scale_factor=2, mode='nearest')\r\n",
        "\r\n",
        "        self.p4_downsample = nn.MaxPool2d(kernel_size=2)\r\n",
        "        self.p5_downsample = nn.MaxPool2d(kernel_size=2)\r\n",
        "        self.p6_downsample = nn.MaxPool2d(kernel_size=2)\r\n",
        "        self.p7_downsample = nn.MaxPool2d(kernel_size=2)\r\n",
        "\r\n",
        "        # Weight\r\n",
        "        self.p6_w1 = nn.Parameter(torch.ones(2))\r\n",
        "        self.p6_w1_relu = nn.ReLU()\r\n",
        "        self.p5_w1 = nn.Parameter(torch.ones(2))\r\n",
        "        self.p5_w1_relu = nn.ReLU()\r\n",
        "        self.p4_w1 = nn.Parameter(torch.ones(2))\r\n",
        "        self.p4_w1_relu = nn.ReLU()\r\n",
        "        self.p3_w1 = nn.Parameter(torch.ones(2))\r\n",
        "        self.p3_w1_relu = nn.ReLU()\r\n",
        "\r\n",
        "        self.p4_w2 = nn.Parameter(torch.ones(3))\r\n",
        "        self.p4_w2_relu = nn.ReLU()\r\n",
        "        self.p5_w2 = nn.Parameter(torch.ones(3))\r\n",
        "        self.p5_w2_relu = nn.ReLU()\r\n",
        "        self.p6_w2 = nn.Parameter(torch.ones(3))\r\n",
        "        self.p6_w2_relu = nn.ReLU()\r\n",
        "        self.p7_w2 = nn.Parameter(torch.ones(2))\r\n",
        "        self.p7_w2_relu = nn.ReLU()\r\n",
        "\r\n",
        "    def forward(self, inputs):\r\n",
        "        \"\"\"\r\n",
        "            P7_0 -------------------------- P7_2 -------->\r\n",
        "\r\n",
        "            P6_0 ---------- P6_1 ---------- P6_2 -------->\r\n",
        "\r\n",
        "            P5_0 ---------- P5_1 ---------- P5_2 -------->\r\n",
        "\r\n",
        "            P4_0 ---------- P4_1 ---------- P4_2 -------->\r\n",
        "\r\n",
        "            P3_0 -------------------------- P3_2 -------->\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        # P3_0, P4_0, P5_0, P6_0 and P7_0\r\n",
        "        p3_in, p4_in, p5_in, p6_in, p7_in = inputs\r\n",
        "        # P7_0 to P7_2\r\n",
        "        # Weights for P6_0 and P7_0 to P6_1\r\n",
        "        p6_w1 = self.p6_w1_relu(self.p6_w1)\r\n",
        "        weight = p6_w1 / (torch.sum(p6_w1, dim=0) + self.epsilon)\r\n",
        "        # Connections for P6_0 and P7_0 to P6_1 respectively\r\n",
        "        p6_up = self.conv6_up(weight[0] * p6_in + weight[1] * self.p6_upsample(p7_in))\r\n",
        "        # Weights for P5_0 and P6_0 to P5_1\r\n",
        "        p5_w1 = self.p5_w1_relu(self.p5_w1)\r\n",
        "        weight = p5_w1 / (torch.sum(p5_w1, dim=0) + self.epsilon)\r\n",
        "        # Connections for P5_0 and P6_0 to P5_1 respectively\r\n",
        "        p5_up = self.conv5_up(weight[0] * p5_in + weight[1] * self.p5_upsample(p6_up))\r\n",
        "        # Weights for P4_0 and P5_0 to P4_1\r\n",
        "        p4_w1 = self.p4_w1_relu(self.p4_w1)\r\n",
        "        weight = p4_w1 / (torch.sum(p4_w1, dim=0) + self.epsilon)\r\n",
        "        # Connections for P4_0 and P5_0 to P4_1 respectively\r\n",
        "        p4_up = self.conv4_up(weight[0] * p4_in + weight[1] * self.p4_upsample(p5_up))\r\n",
        "\r\n",
        "        # Weights for P3_0 and P4_1 to P3_2\r\n",
        "        p3_w1 = self.p3_w1_relu(self.p3_w1)\r\n",
        "        weight = p3_w1 / (torch.sum(p3_w1, dim=0) + self.epsilon)\r\n",
        "        # Connections for P3_0 and P4_1 to P3_2 respectively\r\n",
        "        p3_out = self.conv3_up(weight[0] * p3_in + weight[1] * self.p3_upsample(p4_up))\r\n",
        "\r\n",
        "        # Weights for P4_0, P4_1 and P3_2 to P4_2\r\n",
        "        p4_w2 = self.p4_w2_relu(self.p4_w2)\r\n",
        "        weight = p4_w2 / (torch.sum(p4_w2, dim=0) + self.epsilon)\r\n",
        "        # Connections for P4_0, P4_1 and P3_2 to P4_2 respectively\r\n",
        "        p4_out = self.conv4_down(\r\n",
        "            weight[0] * p4_in + weight[1] * p4_up + weight[2] * self.p4_downsample(p3_out))\r\n",
        "        # Weights for P5_0, P5_1 and P4_2 to P5_2\r\n",
        "        p5_w2 = self.p5_w2_relu(self.p5_w2)\r\n",
        "        weight = p5_w2 / (torch.sum(p5_w2, dim=0) + self.epsilon)\r\n",
        "        # Connections for P5_0, P5_1 and P4_2 to P5_2 respectively\r\n",
        "        p5_out = self.conv5_down(\r\n",
        "            weight[0] * p5_in + weight[1] * p5_up + weight[2] * self.p5_downsample(p4_out))\r\n",
        "        # Weights for P6_0, P6_1 and P5_2 to P6_2\r\n",
        "        p6_w2 = self.p6_w2_relu(self.p6_w2)\r\n",
        "        weight = p6_w2 / (torch.sum(p6_w2, dim=0) + self.epsilon)\r\n",
        "        # Connections for P6_0, P6_1 and P5_2 to P6_2 respectively\r\n",
        "        p6_out = self.conv6_down(\r\n",
        "            weight[0] * p6_in + weight[1] * p6_up + weight[2] * self.p6_downsample(p5_out))\r\n",
        "        # Weights for P7_0 and P6_2 to P7_2\r\n",
        "        p7_w2 = self.p7_w2_relu(self.p7_w2)\r\n",
        "        weight = p7_w2 / (torch.sum(p7_w2, dim=0) + self.epsilon)\r\n",
        "        # Connections for P7_0 and P6_2 to P7_2\r\n",
        "        p7_out = self.conv7_down(weight[0] * p7_in + weight[1] * self.p7_downsample(p6_out))\r\n",
        "\r\n",
        "        return p3_out, p4_out, p5_out, p6_out, p7_out\r\n",
        "\r\n",
        "\r\n",
        "class Regressor(nn.Module):\r\n",
        "    def __init__(self, in_channels, num_anchors, num_layers):\r\n",
        "        super(Regressor, self).__init__()\r\n",
        "        layers = []\r\n",
        "        for _ in range(num_layers):\r\n",
        "            layers.append(nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1))\r\n",
        "            layers.append(nn.ReLU(True))\r\n",
        "        self.layers = nn.Sequential(*layers)\r\n",
        "        self.header = nn.Conv2d(in_channels, num_anchors * 4, kernel_size=3, stride=1, padding=1)\r\n",
        "\r\n",
        "    def forward(self, inputs):\r\n",
        "        inputs = self.layers(inputs)\r\n",
        "        inputs = self.header(inputs)\r\n",
        "        output = inputs.permute(0, 2, 3, 1)\r\n",
        "        return output.contiguous().view(output.shape[0], -1, 4)\r\n",
        "\r\n",
        "\r\n",
        "class Classifier(nn.Module):\r\n",
        "    def __init__(self, in_channels, num_anchors, num_classes, num_layers):\r\n",
        "        super(Classifier, self).__init__()\r\n",
        "        self.num_anchors = num_anchors\r\n",
        "        self.num_classes = num_classes\r\n",
        "        layers = []\r\n",
        "        for _ in range(num_layers):\r\n",
        "            layers.append(nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=1, padding=1))\r\n",
        "            layers.append(nn.ReLU(True))\r\n",
        "        self.layers = nn.Sequential(*layers)\r\n",
        "        self.header = nn.Conv2d(in_channels, num_anchors * num_classes, kernel_size=3, stride=1, padding=1)\r\n",
        "        self.act = nn.Sigmoid()\r\n",
        "\r\n",
        "    def forward(self, inputs):\r\n",
        "        inputs = self.layers(inputs)\r\n",
        "        inputs = self.header(inputs)\r\n",
        "        inputs = self.act(inputs)\r\n",
        "        inputs = inputs.permute(0, 2, 3, 1)\r\n",
        "        output = inputs.contiguous().view(inputs.shape[0], inputs.shape[1], inputs.shape[2], self.num_anchors,\r\n",
        "                                          self.num_classes)\r\n",
        "        return output.contiguous().view(output.shape[0], -1, self.num_classes)\r\n",
        "\r\n",
        "\r\n",
        "class EfficientNet(nn.Module):\r\n",
        "    def __init__(self, ):\r\n",
        "        super(EfficientNet, self).__init__()\r\n",
        "        model = EffNet.from_pretrained('efficientnet-b0')\r\n",
        "        del model._conv_head\r\n",
        "        del model._bn1\r\n",
        "        del model._avg_pooling\r\n",
        "        del model._dropout\r\n",
        "        del model._fc\r\n",
        "        self.model = model\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.model._swish(self.model._bn0(self.model._conv_stem(x)))\r\n",
        "        feature_maps = []\r\n",
        "        for idx, block in enumerate(self.model._blocks):\r\n",
        "            drop_connect_rate = self.model._global_params.drop_connect_rate\r\n",
        "            if drop_connect_rate:\r\n",
        "                drop_connect_rate *= float(idx) / len(self.model._blocks)\r\n",
        "            x = block(x, drop_connect_rate=drop_connect_rate)\r\n",
        "            if block._depthwise_conv.stride == [2, 2]:\r\n",
        "                feature_maps.append(x)\r\n",
        "\r\n",
        "        return feature_maps[1:]\r\n",
        "\r\n",
        "\r\n",
        "class EfficientDet(nn.Module):\r\n",
        "    def __init__(self, num_anchors=9, num_classes=20, compound_coef=0):\r\n",
        "        super(EfficientDet, self).__init__()\r\n",
        "        self.compound_coef = compound_coef\r\n",
        "\r\n",
        "        self.num_channels = [64, 88, 112, 160, 224, 288, 384, 384][self.compound_coef]\r\n",
        "\r\n",
        "        self.conv3 = nn.Conv2d(40, self.num_channels, kernel_size=1, stride=1, padding=0)\r\n",
        "        self.conv4 = nn.Conv2d(80, self.num_channels, kernel_size=1, stride=1, padding=0)\r\n",
        "        self.conv5 = nn.Conv2d(192, self.num_channels, kernel_size=1, stride=1, padding=0)\r\n",
        "        self.conv6 = nn.Conv2d(192, self.num_channels, kernel_size=3, stride=2, padding=1)\r\n",
        "        self.conv7 = nn.Sequential(nn.ReLU(),\r\n",
        "                                   nn.Conv2d(self.num_channels, self.num_channels, kernel_size=3, stride=2, padding=1))\r\n",
        "\r\n",
        "        self.bifpn = nn.Sequential(*[BiFPN(self.num_channels) for _ in range(min(2 + self.compound_coef, 8))])\r\n",
        "\r\n",
        "        self.num_classes = num_classes\r\n",
        "        self.regressor = Regressor(in_channels=self.num_channels, num_anchors=num_anchors,\r\n",
        "                                   num_layers=3 + self.compound_coef // 3)\r\n",
        "        self.classifier = Classifier(in_channels=self.num_channels, num_anchors=num_anchors, num_classes=num_classes,\r\n",
        "                                     num_layers=3 + self.compound_coef // 3)\r\n",
        "\r\n",
        "        self.anchors = Anchors()\r\n",
        "        self.regressBoxes = BBoxTransform()\r\n",
        "        self.clipBoxes = ClipBoxes()\r\n",
        "        self.focalLoss = FocalLoss()\r\n",
        "\r\n",
        "        for m in self.modules():\r\n",
        "            if isinstance(m, nn.Conv2d):\r\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\r\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\r\n",
        "            elif isinstance(m, nn.BatchNorm2d):\r\n",
        "                m.weight.data.fill_(1)\r\n",
        "                m.bias.data.zero_()\r\n",
        "\r\n",
        "        prior = 0.01\r\n",
        "\r\n",
        "        self.classifier.header.weight.data.fill_(0)\r\n",
        "        self.classifier.header.bias.data.fill_(-math.log((1.0 - prior) / prior))\r\n",
        "\r\n",
        "        self.regressor.header.weight.data.fill_(0)\r\n",
        "        self.regressor.header.bias.data.fill_(0)\r\n",
        "\r\n",
        "        self.backbone_net = EfficientNet()\r\n",
        "\r\n",
        "    def freeze_bn(self):\r\n",
        "        for m in self.modules():\r\n",
        "            if isinstance(m, nn.BatchNorm2d):\r\n",
        "                m.eval()\r\n",
        "\r\n",
        "    def forward(self, inputs):\r\n",
        "        if len(inputs) == 2:\r\n",
        "            is_training = True\r\n",
        "            img_batch, annotations = inputs\r\n",
        "        else:\r\n",
        "            is_training = False\r\n",
        "            img_batch = inputs\r\n",
        "\r\n",
        "        c3, c4, c5 = self.backbone_net(img_batch)\r\n",
        "        p3 = self.conv3(c3)\r\n",
        "        p4 = self.conv4(c4)\r\n",
        "        p5 = self.conv5(c5)\r\n",
        "        p6 = self.conv6(c5)\r\n",
        "        p7 = self.conv7(p6)\r\n",
        "\r\n",
        "        features = [p3, p4, p5, p6, p7]\r\n",
        "        features = self.bifpn(features)\r\n",
        "\r\n",
        "        regression = torch.cat([self.regressor(feature) for feature in features], dim=1)\r\n",
        "        classification = torch.cat([self.classifier(feature) for feature in features], dim=1)\r\n",
        "        anchors = self.anchors(img_batch)\r\n",
        "\r\n",
        "        if is_training:\r\n",
        "            return self.focalLoss(classification, regression, anchors, annotations)\r\n",
        "        else:\r\n",
        "            transformed_anchors = self.regressBoxes(anchors, regression)\r\n",
        "            transformed_anchors = self.clipBoxes(transformed_anchors, img_batch)\r\n",
        "\r\n",
        "            scores = torch.max(classification, dim=2, keepdim=True)[0]\r\n",
        "\r\n",
        "            scores_over_thresh = (scores > 0.05)[0, :, 0]\r\n",
        "\r\n",
        "            if scores_over_thresh.sum() == 0:\r\n",
        "                return [torch.zeros(0), torch.zeros(0), torch.zeros(0, 4)]\r\n",
        "\r\n",
        "            classification = classification[:, scores_over_thresh, :]\r\n",
        "            transformed_anchors = transformed_anchors[:, scores_over_thresh, :]\r\n",
        "            scores = scores[:, scores_over_thresh, :]\r\n",
        "\r\n",
        "            anchors_nms_idx = nms(torch.cat([transformed_anchors, scores], dim=2)[0, :, :], 0.5)\r\n",
        "\r\n",
        "            nms_scores, nms_class = classification[0, anchors_nms_idx, :].max(dim=1)\r\n",
        "\r\n",
        "            return [nms_scores, nms_class, transformed_anchors[0, anchors_nms_idx, :]]\r\n",
        "\r\n",
        "\r\n",
        "if __name__ == '__main__':\r\n",
        "    from tensorboardX import SummaryWriter\r\n",
        "    def count_parameters(model):\r\n",
        "        return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "    model = EfficientDet(num_classes=80)\r\n",
        "    print (count_parameters(model))\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span></span><progress style='margin:2px 4px;' max='21388428' value='21388428'></progress>100% 20.4M/20.4M [00:00&lt;00:00, 73.5MB/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded pretrained weights for efficientnet-b0\n",
            "4499798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Lm4ohZg-F-e"
      },
      "source": [
        "# Training Agent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avBEBUWv-T8P"
      },
      "source": [
        "import os\r\n",
        "import argparse\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torchvision import transforms\r\n",
        "from tensorboardX import SummaryWriter\r\n",
        "import shutil\r\n",
        "import numpy as np\r\n",
        "from tqdm.autonotebook import tqdm\r\n",
        "\r\n",
        "\r\n",
        "class Detector():\r\n",
        "    def __init__(self, verbose=1):\r\n",
        "        self.system_dict = {};\r\n",
        "        self.system_dict[\"verbose\"] = verbose;\r\n",
        "        self.system_dict[\"local\"] = {};\r\n",
        "        self.system_dict[\"dataset\"] = {};\r\n",
        "        self.system_dict[\"dataset\"][\"train\"] = {};\r\n",
        "        self.system_dict[\"dataset\"][\"val\"] = {};\r\n",
        "        self.system_dict[\"dataset\"][\"val\"][\"status\"] = False;\r\n",
        "\r\n",
        "        self.system_dict[\"params\"] = {};\r\n",
        "        self.system_dict[\"params\"][\"image_size\"] = 512;\r\n",
        "        self.system_dict[\"params\"][\"batch_size\"] = 8;\r\n",
        "        self.system_dict[\"params\"][\"num_workers\"] = 3;\r\n",
        "        self.system_dict[\"params\"][\"use_gpu\"] = True;\r\n",
        "        self.system_dict[\"params\"][\"gpu_devices\"] = [0];\r\n",
        "        self.system_dict[\"params\"][\"lr\"] = 0.0001;\r\n",
        "        self.system_dict[\"params\"][\"num_epochs\"] = 10;\r\n",
        "        self.system_dict[\"params\"][\"val_interval\"] = 1;\r\n",
        "        self.system_dict[\"params\"][\"es_min_delta\"] = 0.0;\r\n",
        "        self.system_dict[\"params\"][\"es_patience\"] = 0;\r\n",
        "\r\n",
        "\r\n",
        "        self.system_dict[\"output\"] = {};\r\n",
        "        self.system_dict[\"output\"][\"log_path\"] = \"tensorboard/signatrix_efficientdet_coco\";\r\n",
        "        self.system_dict[\"output\"][\"saved_path\"] = \"trained/\";\r\n",
        "        self.system_dict[\"output\"][\"best_epoch\"] = 0;\r\n",
        "        self.system_dict[\"output\"][\"best_loss\"] = 1e5;\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def Train_Dataset(self, root_dir, coco_dir, img_dir, set_dir, batch_size=8, image_size=512, use_gpu=True, num_workers=3):\r\n",
        "        self.system_dict[\"dataset\"][\"train\"][\"root_dir\"] = root_dir;\r\n",
        "        self.system_dict[\"dataset\"][\"train\"][\"coco_dir\"] = coco_dir;\r\n",
        "        self.system_dict[\"dataset\"][\"train\"][\"img_dir\"] = img_dir;\r\n",
        "        self.system_dict[\"dataset\"][\"train\"][\"set_dir\"] = set_dir;\r\n",
        "\r\n",
        "\r\n",
        "        self.system_dict[\"params\"][\"batch_size\"] = batch_size;\r\n",
        "        self.system_dict[\"params\"][\"image_size\"] = image_size;\r\n",
        "        self.system_dict[\"params\"][\"use_gpu\"] = use_gpu;\r\n",
        "        self.system_dict[\"params\"][\"num_workers\"] = num_workers;\r\n",
        "\r\n",
        "        if(self.system_dict[\"params\"][\"use_gpu\"]):\r\n",
        "            if torch.cuda.is_available():\r\n",
        "                self.system_dict[\"local\"][\"num_gpus\"] = torch.cuda.device_count()\r\n",
        "                torch.cuda.manual_seed(123)\r\n",
        "            else:\r\n",
        "                self.system_dict[\"local\"][\"num_gpus\"] = 1\r\n",
        "                torch.manual_seed(123)\r\n",
        "\r\n",
        "        self.system_dict[\"local\"][\"training_params\"] = {\"batch_size\": self.system_dict[\"params\"][\"batch_size\"] * self.system_dict[\"local\"][\"num_gpus\"],\r\n",
        "                                                           \"shuffle\": True,\r\n",
        "                                                           \"drop_last\": True,\r\n",
        "                                                           \"collate_fn\": collater,\r\n",
        "                                                           \"num_workers\": self.system_dict[\"params\"][\"num_workers\"]}\r\n",
        "\r\n",
        "        self.system_dict[\"local\"][\"training_set\"] = CocoDataset(root_dir=self.system_dict[\"dataset\"][\"train\"][\"root_dir\"] + \"/\" + self.system_dict[\"dataset\"][\"train\"][\"coco_dir\"],\r\n",
        "                                                            img_dir = self.system_dict[\"dataset\"][\"train\"][\"img_dir\"],\r\n",
        "                                                            set_dir = self.system_dict[\"dataset\"][\"train\"][\"set_dir\"],\r\n",
        "                                                            transform = transforms.Compose([Normalizer(), Augmenter(), Resizer()]))\r\n",
        "        \r\n",
        "        self.system_dict[\"local\"][\"training_generator\"] = DataLoader(self.system_dict[\"local\"][\"training_set\"], \r\n",
        "                                                                    **self.system_dict[\"local\"][\"training_params\"]);\r\n",
        "\r\n",
        "\r\n",
        "    def Val_Dataset(self, root_dir, coco_dir, img_dir, set_dir):\r\n",
        "        self.system_dict[\"dataset\"][\"val\"][\"status\"] = True;\r\n",
        "        self.system_dict[\"dataset\"][\"val\"][\"root_dir\"] = root_dir;\r\n",
        "        self.system_dict[\"dataset\"][\"val\"][\"coco_dir\"] = coco_dir;\r\n",
        "        self.system_dict[\"dataset\"][\"val\"][\"img_dir\"] = img_dir;\r\n",
        "        self.system_dict[\"dataset\"][\"val\"][\"set_dir\"] = set_dir;     \r\n",
        "\r\n",
        "        self.system_dict[\"local\"][\"val_params\"] = {\"batch_size\": self.system_dict[\"params\"][\"batch_size\"],\r\n",
        "                                                   \"shuffle\": False,\r\n",
        "                                                   \"drop_last\": False,\r\n",
        "                                                   \"collate_fn\": collater,\r\n",
        "                                                   \"num_workers\": self.system_dict[\"params\"][\"num_workers\"]}\r\n",
        "\r\n",
        "        self.system_dict[\"local\"][\"val_set\"] = CocoDataset(root_dir=self.system_dict[\"dataset\"][\"val\"][\"root_dir\"] + \"/\" + self.system_dict[\"dataset\"][\"val\"][\"coco_dir\"], \r\n",
        "                                                    img_dir = self.system_dict[\"dataset\"][\"val\"][\"img_dir\"],\r\n",
        "                                                    set_dir = self.system_dict[\"dataset\"][\"val\"][\"set_dir\"],\r\n",
        "                                                    transform=transforms.Compose([Normalizer(), Resizer()]))\r\n",
        "        \r\n",
        "        self.system_dict[\"local\"][\"test_generator\"] = DataLoader(self.system_dict[\"local\"][\"val_set\"], \r\n",
        "                                                                **self.system_dict[\"local\"][\"val_params\"])\r\n",
        "\r\n",
        "\r\n",
        "    def Model(self,gpu_devices=[0]):\r\n",
        "        num_classes = self.system_dict[\"local\"][\"training_set\"].num_classes();\r\n",
        "        efficientdet = EfficientDet(num_classes=num_classes)\r\n",
        "\r\n",
        "        if self.system_dict[\"params\"][\"use_gpu\"]:\r\n",
        "            self.system_dict[\"params\"][\"gpu_devices\"] = gpu_devices\r\n",
        "            if len(self.system_dict[\"params\"][\"gpu_devices\"])==1:\r\n",
        "                os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(self.system_dict[\"params\"][\"gpu_devices\"][0])\r\n",
        "            else:\r\n",
        "                os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join([str(id) for id in self.system_dict[\"params\"][\"gpu_devices\"]])\r\n",
        "            self.system_dict[\"local\"][\"device\"] = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "            efficientdet = efficientdet.to(self.system_dict[\"local\"][\"device\"])\r\n",
        "            efficientdet= torch.nn.DataParallel(efficientdet).to(self.system_dict[\"local\"][\"device\"])\r\n",
        "\r\n",
        "        self.system_dict[\"local\"][\"model\"] = efficientdet;\r\n",
        "        self.system_dict[\"local\"][\"model\"].train();\r\n",
        "\r\n",
        "\r\n",
        "    def Set_Hyperparams(self, lr=0.0001, val_interval=1, es_min_delta=0.0, es_patience=0):\r\n",
        "        self.system_dict[\"params\"][\"lr\"] = lr;\r\n",
        "        self.system_dict[\"params\"][\"val_interval\"] = val_interval;\r\n",
        "        self.system_dict[\"params\"][\"es_min_delta\"] = es_min_delta;\r\n",
        "        self.system_dict[\"params\"][\"es_patience\"] = es_patience;\r\n",
        "\r\n",
        "\r\n",
        "        self.system_dict[\"local\"][\"optimizer\"] = torch.optim.Adam(self.system_dict[\"local\"][\"model\"].parameters(), \r\n",
        "                                                                    self.system_dict[\"params\"][\"lr\"]);\r\n",
        "\r\n",
        "        self.system_dict[\"local\"][\"scheduler\"] = torch.optim.lr_scheduler.ReduceLROnPlateau(self.system_dict[\"local\"][\"optimizer\"], \r\n",
        "                                                                    patience=3, verbose=True)\r\n",
        "\r\n",
        "\r\n",
        "    def Train(self, num_epochs=2, model_output_dir=\"trained/\"):\r\n",
        "        self.system_dict[\"output\"][\"log_path\"] = \"tensorboard/signatrix_efficientdet_coco\";\r\n",
        "        self.system_dict[\"output\"][\"saved_path\"] = model_output_dir;\r\n",
        "        self.system_dict[\"params\"][\"num_epochs\"] = num_epochs;\r\n",
        "\r\n",
        "        if os.path.isdir(self.system_dict[\"output\"][\"log_path\"]):\r\n",
        "            shutil.rmtree(self.system_dict[\"output\"][\"log_path\"])\r\n",
        "        os.makedirs(self.system_dict[\"output\"][\"log_path\"])\r\n",
        "\r\n",
        "        if os.path.isdir(self.system_dict[\"output\"][\"saved_path\"]):\r\n",
        "            shutil.rmtree(self.system_dict[\"output\"][\"saved_path\"])\r\n",
        "        os.makedirs(self.system_dict[\"output\"][\"saved_path\"])\r\n",
        "\r\n",
        "        writer = SummaryWriter(self.system_dict[\"output\"][\"log_path\"])\r\n",
        "\r\n",
        "        num_iter_per_epoch = len(self.system_dict[\"local\"][\"training_generator\"])\r\n",
        "\r\n",
        "        if(self.system_dict[\"dataset\"][\"val\"][\"status\"]):\r\n",
        "            \r\n",
        "            for epoch in range(self.system_dict[\"params\"][\"num_epochs\"]):\r\n",
        "                self.system_dict[\"local\"][\"model\"].train()\r\n",
        "\r\n",
        "                epoch_loss = []\r\n",
        "                progress_bar = tqdm(self.system_dict[\"local\"][\"training_generator\"])\r\n",
        "                for iter, data in enumerate(progress_bar):\r\n",
        "                    try:\r\n",
        "                        self.system_dict[\"local\"][\"optimizer\"].zero_grad()\r\n",
        "                        if torch.cuda.is_available():\r\n",
        "                            cls_loss, reg_loss = self.system_dict[\"local\"][\"model\"]([data['img'].to(self.system_dict[\"local\"][\"device\"]).float(), data['annot'].to(self.system_dict[\"local\"][\"device\"])])\r\n",
        "                        else:\r\n",
        "                            cls_loss, reg_loss = self.system_dict[\"local\"][\"model\"]([data['img'].float(), data['annot']])\r\n",
        "\r\n",
        "                        cls_loss = cls_loss.mean()\r\n",
        "                        reg_loss = reg_loss.mean()\r\n",
        "                        loss = cls_loss + reg_loss\r\n",
        "                        if loss == 0:\r\n",
        "                            continue\r\n",
        "                        loss.backward()\r\n",
        "                        torch.nn.utils.clip_grad_norm_(self.system_dict[\"local\"][\"model\"].parameters(), 0.1)\r\n",
        "                        self.system_dict[\"local\"][\"optimizer\"].step()\r\n",
        "                        epoch_loss.append(float(loss))\r\n",
        "                        total_loss = np.mean(epoch_loss)\r\n",
        "                        print( \r\n",
        "                            'Epoch: {}/{}. Iteration: {}/{}. Cls loss: {:.5f}. Reg loss: {:.5f}. Batch loss: {:.5f} Total loss: {:.5f}'.format(\r\n",
        "                                epoch + 1, self.system_dict[\"params\"][\"num_epochs\"], iter + 1, num_iter_per_epoch, cls_loss, reg_loss, loss,\r\n",
        "                                total_loss))\r\n",
        "                        progress_bar.set_description(\r\n",
        "                            'Epoch: {}/{}. Iteration: {}/{}. Cls loss: {:.5f}. Reg loss: {:.5f}. Batch loss: {:.5f} Total loss: {:.5f}'.format(\r\n",
        "                                epoch + 1, self.system_dict[\"params\"][\"num_epochs\"], iter + 1, num_iter_per_epoch, cls_loss, reg_loss, loss,\r\n",
        "                                total_loss))\r\n",
        "                        writer.add_scalar('Train/Total_loss', total_loss, epoch * num_iter_per_epoch + iter)\r\n",
        "                        writer.add_scalar('Train/Regression_loss', reg_loss, epoch * num_iter_per_epoch + iter)\r\n",
        "                        writer.add_scalar('Train/Classfication_loss (focal loss)', cls_loss, epoch * num_iter_per_epoch + iter)\r\n",
        "\r\n",
        "                    except Exception as e:\r\n",
        "                        print(e)\r\n",
        "                        continue\r\n",
        "                self.system_dict[\"local\"][\"scheduler\"].step(np.mean(epoch_loss))\r\n",
        "\r\n",
        "                if epoch % self.system_dict[\"params\"][\"val_interval\"] == 0:\r\n",
        "\r\n",
        "                    self.system_dict[\"local\"][\"model\"].eval()\r\n",
        "                    loss_regression_ls = []\r\n",
        "                    loss_classification_ls = []\r\n",
        "                    for iter, data in enumerate(self.system_dict[\"local\"][\"test_generator\"]):\r\n",
        "                        with torch.no_grad():\r\n",
        "                            if torch.cuda.is_available():\r\n",
        "                                cls_loss, reg_loss = self.system_dict[\"local\"][\"model\"]([data['img'].to(self.system_dict[\"local\"][\"device\"]).float(), data['annot'].to(self.system_dict[\"local\"][\"device\"])])\r\n",
        "                            else:\r\n",
        "                                cls_loss, reg_loss = self.system_dict[\"local\"][\"model\"]([data['img'].float(), data['annot']])\r\n",
        "\r\n",
        "                            cls_loss = cls_loss.mean()\r\n",
        "                            reg_loss = reg_loss.mean()\r\n",
        "\r\n",
        "                            loss_classification_ls.append(float(cls_loss))\r\n",
        "                            loss_regression_ls.append(float(reg_loss))\r\n",
        "\r\n",
        "                    cls_loss = np.mean(loss_classification_ls)\r\n",
        "                    reg_loss = np.mean(loss_regression_ls)\r\n",
        "                    loss = cls_loss + reg_loss\r\n",
        "\r\n",
        "                    print(\r\n",
        "                        'Epoch: {}/{}. Classification loss: {:1.5f}. Regression loss: {:1.5f}. Total loss: {:1.5f}'.format(\r\n",
        "                            epoch + 1, self.system_dict[\"params\"][\"num_epochs\"], cls_loss, reg_loss,\r\n",
        "                            np.mean(loss)))\r\n",
        "                    writer.add_scalar('Val/Total_loss', loss, epoch)\r\n",
        "                    writer.add_scalar('Val/Regression_loss', reg_loss, epoch)\r\n",
        "                    writer.add_scalar('Val/Classfication_loss (focal loss)', cls_loss, epoch)\r\n",
        "\r\n",
        "                    if loss + self.system_dict[\"params\"][\"es_min_delta\"] < self.system_dict[\"output\"][\"best_loss\"]:\r\n",
        "                        self.system_dict[\"output\"][\"best_loss\"] = loss\r\n",
        "                        self.system_dict[\"output\"][\"best_epoch\"] = epoch\r\n",
        "                        torch.save(self.system_dict[\"local\"][\"model\"], \r\n",
        "                            os.path.join(self.system_dict[\"output\"][\"saved_path\"], \"signatrix_efficientdet_coco.pth\"))\r\n",
        "\r\n",
        "                        dummy_input = torch.rand(1, 3, 512, 512)\r\n",
        "                        if torch.cuda.is_available():\r\n",
        "                            dummy_input = dummy_input.cuda()\r\n",
        "                        if isinstance(self.system_dict[\"local\"][\"model\"], nn.DataParallel):\r\n",
        "                            self.system_dict[\"local\"][\"model\"].module.backbone_net.model.set_swish(memory_efficient=False)\r\n",
        "\r\n",
        "                            torch.onnx.export(self.system_dict[\"local\"][\"model\"].module, dummy_input,\r\n",
        "                                              os.path.join(self.system_dict[\"output\"][\"saved_path\"], \"signatrix_efficientdet_coco.onnx\"),\r\n",
        "                                              verbose=False,\r\n",
        "                                              opset_version=11)\r\n",
        "                            self.system_dict[\"local\"][\"model\"].module.backbone_net.model.set_swish(memory_efficient=True)\r\n",
        "                        else:\r\n",
        "                            self.system_dict[\"local\"][\"model\"].backbone_net.model.set_swish(memory_efficient=False)\r\n",
        "\r\n",
        "                            torch.onnx.export(self.system_dict[\"local\"][\"model\"], dummy_input,\r\n",
        "                                              os.path.join(self.system_dict[\"output\"][\"saved_path\"], \"signatrix_efficientdet_coco.onnx\"),\r\n",
        "                                              verbose=False,\r\n",
        "                                              opset_version = 11)\r\n",
        "                            self.system_dict[\"local\"][\"model\"].backbone_net.model.set_swish(memory_efficient=True)\r\n",
        "\r\n",
        "                    # Early stopping\r\n",
        "                    if epoch - self.system_dict[\"output\"][\"best_epoch\"] > self.system_dict[\"params\"][\"es_patience\"] > 0:\r\n",
        "                        print(\"Stop training at epoch {}. The lowest loss achieved is {}\".format(epoch, loss))\r\n",
        "                        break\r\n",
        "\r\n",
        "        else:\r\n",
        "            for epoch in range(self.system_dict[\"params\"][\"num_epochs\"]):\r\n",
        "                self.system_dict[\"local\"][\"model\"].train()\r\n",
        "\r\n",
        "                epoch_loss = []\r\n",
        "                progress_bar = tqdm(self.system_dict[\"local\"][\"training_generator\"])\r\n",
        "                for iter, data in enumerate(progress_bar):\r\n",
        "                    try:\r\n",
        "                        self.system_dict[\"local\"][\"optimizer\"].zero_grad()\r\n",
        "                        if torch.cuda.is_available():\r\n",
        "                            cls_loss, reg_loss = self.system_dict[\"local\"][\"model\"]([data['img'].to(self.system_dict[\"local\"][\"device\"]).float(), data['annot'].to(self.system_dict[\"local\"][\"device\"])])\r\n",
        "                        else:\r\n",
        "                            cls_loss, reg_loss = self.system_dict[\"local\"][\"model\"]([data['img'].float(), data['annot']])\r\n",
        "\r\n",
        "                        cls_loss = cls_loss.mean()\r\n",
        "                        reg_loss = reg_loss.mean()\r\n",
        "                        loss = cls_loss + reg_loss\r\n",
        "                        if loss == 0:\r\n",
        "                            continue\r\n",
        "                        loss.backward()\r\n",
        "                        torch.nn.utils.clip_grad_norm_(self.system_dict[\"local\"][\"model\"].parameters(), 0.1)\r\n",
        "                        self.system_dict[\"local\"][\"optimizer\"].step()\r\n",
        "                        epoch_loss.append(float(loss))\r\n",
        "                        total_loss = np.mean(epoch_loss)\r\n",
        "\r\n",
        "                        progress_bar.set_description(\r\n",
        "                            'Epoch: {}/{}. Iteration: {}/{}. Cls loss: {:.5f}. Reg loss: {:.5f}. Batch loss: {:.5f} Total loss: {:.5f}'.format(\r\n",
        "                                epoch + 1, self.system_dict[\"params\"][\"num_epochs\"], iter + 1, num_iter_per_epoch, cls_loss, reg_loss, loss,\r\n",
        "                                total_loss))\r\n",
        "                        writer.add_scalar('Train/Total_loss', total_loss, epoch * num_iter_per_epoch + iter)\r\n",
        "                        writer.add_scalar('Train/Regression_loss', reg_loss, epoch * num_iter_per_epoch + iter)\r\n",
        "                        writer.add_scalar('Train/Classfication_loss (focal loss)', cls_loss, epoch * num_iter_per_epoch + iter)\r\n",
        "\r\n",
        "                    except Exception as e:\r\n",
        "                        print(e)\r\n",
        "                        continue\r\n",
        "                self.system_dict[\"local\"][\"scheduler\"].step(np.mean(epoch_loss))\r\n",
        "\r\n",
        "\r\n",
        "                torch.save(self.system_dict[\"local\"][\"model\"], \r\n",
        "                    os.path.join(self.system_dict[\"output\"][\"saved_path\"], \"signatrix_efficientdet_coco.pth\"))\r\n",
        "\r\n",
        "                dummy_input = torch.rand(1, 3, 512, 512)\r\n",
        "                if torch.cuda.is_available():\r\n",
        "                    dummy_input = dummy_input.to(self.system_dict[\"local\"][\"device\"])\r\n",
        "                if isinstance(self.system_dict[\"local\"][\"model\"], nn.DataParallel):\r\n",
        "                    self.system_dict[\"local\"][\"model\"].module.backbone_net.model.set_swish(memory_efficient=False)\r\n",
        "\r\n",
        "                    try:\r\n",
        "                        torch.onnx.export(self.system_dict[\"local\"][\"model\"].module, dummy_input,\r\n",
        "                                          os.path.join(self.system_dict[\"output\"][\"saved_path\"], \"signatrix_efficientdet_coco.onnx\"),\r\n",
        "                                          verbose=False,\r\n",
        "                                          opset_version=11)\r\n",
        "                    except:\r\n",
        "                        print('faild onnx export')\r\n",
        "                        continue\r\n",
        "                    self.system_dict[\"local\"][\"model\"].module.backbone_net.model.set_swish(memory_efficient=True)\r\n",
        "                else:\r\n",
        "                    self.system_dict[\"local\"][\"model\"].backbone_net.model.set_swish(memory_efficient=False)\r\n",
        "\r\n",
        "                    torch.onnx.export(self.system_dict[\"local\"][\"model\"], dummy_input,\r\n",
        "                                      os.path.join(self.system_dict[\"output\"][\"saved_path\"], \"signatrix_efficientdet_coco.onnx\"),\r\n",
        "                                      verbose=False,\r\n",
        "                                      opset_version=11)\r\n",
        "                    self.system_dict[\"local\"][\"model\"].backbone_net.model.set_swish(memory_efficient=True)\r\n",
        "\r\n",
        "\r\n",
        "        writer.close()\r\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5l9rWmT-v-1",
        "outputId": "5057e562-b20d-490a-8f66-9a07452449cd"
      },
      "source": [
        "gtf = Detector()\r\n",
        "\r\n",
        "#directs the model towards file structure\r\n",
        "root_dir = \"./\";\r\n",
        "coco_dir = \"space/Fruit\";\r\n",
        "img_dir = \"./\";\r\n",
        "set_dir = \"Images\";\r\n",
        "\r\n",
        "gtf.Train_Dataset(root_dir, coco_dir, img_dir, set_dir, batch_size=8, image_size=512, use_gpu=True, num_workers=4)\r\n",
        "gtf.Model()\r\n",
        "gtf.Set_Hyperparams(lr=0.0001, val_interval=1, es_min_delta=0.0, es_patience=0)\r\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Loaded pretrained weights for efficientnet-b0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFF9gdeJ_FNz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1cf6bb7a-1027-490e-bcbd-c2cec6075d08"
      },
      "source": [
        "%%time\r\n",
        "gtf.Train(num_epochs=100, model_output_dir=\"trained_weight/\");"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 1/100. Iteration: 16/16. Cls loss: 0.63099. Reg loss: 0.93906. Batch loss: 1.57006 Total loss: 1.88663</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.72it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:249: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:96: TracerWarning: torch.from_numpy results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:280: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 2/100. Iteration: 16/16. Cls loss: 0.41429. Reg loss: 0.70459. Batch loss: 1.11888 Total loss: 1.26703</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.70it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 3/100. Iteration: 16/16. Cls loss: 0.33105. Reg loss: 0.54548. Batch loss: 0.87653 Total loss: 0.99192</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.69it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 4/100. Iteration: 16/16. Cls loss: 0.27718. Reg loss: 0.57059. Batch loss: 0.84777 Total loss: 0.82834</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 5/100. Iteration: 16/16. Cls loss: 0.34305. Reg loss: 0.55593. Batch loss: 0.89898 Total loss: 0.77039</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.70it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 6/100. Iteration: 16/16. Cls loss: 0.22196. Reg loss: 0.40311. Batch loss: 0.62507 Total loss: 0.70022</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 7/100. Iteration: 16/16. Cls loss: 0.21997. Reg loss: 0.46038. Batch loss: 0.68035 Total loss: 0.65635</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 8/100. Iteration: 16/16. Cls loss: 0.17604. Reg loss: 0.38303. Batch loss: 0.55907 Total loss: 0.62788</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.69it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 9/100. Iteration: 16/16. Cls loss: 0.13809. Reg loss: 0.37807. Batch loss: 0.51616 Total loss: 0.59166</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.69it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 10/100. Iteration: 16/16. Cls loss: 0.17489. Reg loss: 0.40369. Batch loss: 0.57858 Total loss: 0.56211</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/symbolic_opset9.py:2332: UserWarning: Exporting aten::index operator with indices of type Byte. Only 1-D indices are supported. In any other case, this will produce an incorrect ONNX graph.\n",
            "  warnings.warn(\"Exporting aten::index operator with indices of type Byte. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/symbolic_opset9.py:588: UserWarning: This model contains a squeeze operation on dimension 1 on an input with unknown shape. Note that if the size of dimension 1 of the input is not 1, the ONNX model will return an error. Opset version 11 supports squeezing on non-singleton dimensions, it is recommended to export this model using opset version 11 or higher.\n",
            "  \"version 11 or higher.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 11/100. Iteration: 16/16. Cls loss: 0.24201. Reg loss: 0.42840. Batch loss: 0.67041 Total loss: 0.56780</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.69it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 12/100. Iteration: 16/16. Cls loss: 0.11649. Reg loss: 0.29905. Batch loss: 0.41554 Total loss: 0.51355</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.69it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 13/100. Iteration: 16/16. Cls loss: 0.14435. Reg loss: 0.33664. Batch loss: 0.48100 Total loss: 0.49393</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 14/100. Iteration: 16/16. Cls loss: 0.09536. Reg loss: 0.26792. Batch loss: 0.36328 Total loss: 0.48789</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 15/100. Iteration: 16/16. Cls loss: 0.13991. Reg loss: 0.35814. Batch loss: 0.49805 Total loss: 0.46084</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 16/100. Iteration: 16/16. Cls loss: 0.09505. Reg loss: 0.30000. Batch loss: 0.39505 Total loss: 0.44845</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 17/100. Iteration: 16/16. Cls loss: 0.09738. Reg loss: 0.30205. Batch loss: 0.39943 Total loss: 0.44006</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 18/100. Iteration: 16/16. Cls loss: 0.08979. Reg loss: 0.23878. Batch loss: 0.32858 Total loss: 0.41195</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.70it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 19/100. Iteration: 16/16. Cls loss: 0.13516. Reg loss: 0.26140. Batch loss: 0.39656 Total loss: 0.39791</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 20/100. Iteration: 16/16. Cls loss: 0.05822. Reg loss: 0.23182. Batch loss: 0.29004 Total loss: 0.39378</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 21/100. Iteration: 16/16. Cls loss: 0.11706. Reg loss: 0.29008. Batch loss: 0.40715 Total loss: 0.37903</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 22/100. Iteration: 16/16. Cls loss: 0.09018. Reg loss: 0.26171. Batch loss: 0.35189 Total loss: 0.37542</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 23/100. Iteration: 16/16. Cls loss: 0.07734. Reg loss: 0.25334. Batch loss: 0.33069 Total loss: 0.36513</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.66it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 24/100. Iteration: 16/16. Cls loss: 0.13640. Reg loss: 0.25779. Batch loss: 0.39419 Total loss: 0.34630</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 25/100. Iteration: 16/16. Cls loss: 0.05666. Reg loss: 0.27371. Batch loss: 0.33037 Total loss: 0.32904</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 26/100. Iteration: 16/16. Cls loss: 0.12149. Reg loss: 0.19559. Batch loss: 0.31709 Total loss: 0.30448</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 27/100. Iteration: 16/16. Cls loss: 0.04655. Reg loss: 0.15472. Batch loss: 0.20127 Total loss: 0.32009</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.69it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 28/100. Iteration: 16/16. Cls loss: 0.05412. Reg loss: 0.19172. Batch loss: 0.24583 Total loss: 0.32645</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 29/100. Iteration: 16/16. Cls loss: 0.10981. Reg loss: 0.27827. Batch loss: 0.38808 Total loss: 0.29025</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 30/100. Iteration: 16/16. Cls loss: 0.05396. Reg loss: 0.17316. Batch loss: 0.22712 Total loss: 0.29243</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 31/100. Iteration: 16/16. Cls loss: 0.13145. Reg loss: 0.18155. Batch loss: 0.31300 Total loss: 0.27797</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 32/100. Iteration: 16/16. Cls loss: 0.05302. Reg loss: 0.25235. Batch loss: 0.30537 Total loss: 0.26172</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 33/100. Iteration: 16/16. Cls loss: 0.05409. Reg loss: 0.18323. Batch loss: 0.23731 Total loss: 0.25913</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 34/100. Iteration: 16/16. Cls loss: 0.06424. Reg loss: 0.24394. Batch loss: 0.30818 Total loss: 0.26535</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.66it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 35/100. Iteration: 16/16. Cls loss: 0.05228. Reg loss: 0.15773. Batch loss: 0.21001 Total loss: 0.26208</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 36/100. Iteration: 16/16. Cls loss: 0.05642. Reg loss: 0.16257. Batch loss: 0.21899 Total loss: 0.24840</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.70it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 37/100. Iteration: 16/16. Cls loss: 0.04778. Reg loss: 0.25314. Batch loss: 0.30092 Total loss: 0.25013</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 38/100. Iteration: 16/16. Cls loss: 0.04542. Reg loss: 0.19930. Batch loss: 0.24472 Total loss: 0.23729</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 39/100. Iteration: 16/16. Cls loss: 0.06998. Reg loss: 0.17252. Batch loss: 0.24249 Total loss: 0.23854</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 40/100. Iteration: 16/16. Cls loss: 0.05539. Reg loss: 0.25082. Batch loss: 0.30622 Total loss: 0.22489</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 41/100. Iteration: 16/16. Cls loss: 0.07016. Reg loss: 0.11575. Batch loss: 0.18591 Total loss: 0.22608</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.66it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 42/100. Iteration: 16/16. Cls loss: 0.03041. Reg loss: 0.12679. Batch loss: 0.15720 Total loss: 0.20436</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 43/100. Iteration: 16/16. Cls loss: 0.03081. Reg loss: 0.11998. Batch loss: 0.15079 Total loss: 0.19950</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 44/100. Iteration: 16/16. Cls loss: 0.03041. Reg loss: 0.17503. Batch loss: 0.20544 Total loss: 0.20334</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 45/100. Iteration: 16/16. Cls loss: 0.02527. Reg loss: 0.12734. Batch loss: 0.15260 Total loss: 0.19309</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 46/100. Iteration: 16/16. Cls loss: 0.06787. Reg loss: 0.16649. Batch loss: 0.23435 Total loss: 0.19632</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 47/100. Iteration: 16/16. Cls loss: 0.05348. Reg loss: 0.16158. Batch loss: 0.21506 Total loss: 0.18704</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 48/100. Iteration: 16/16. Cls loss: 0.05788. Reg loss: 0.17389. Batch loss: 0.23177 Total loss: 0.19786</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.64it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 49/100. Iteration: 16/16. Cls loss: 0.02575. Reg loss: 0.14556. Batch loss: 0.17131 Total loss: 0.17171</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 50/100. Iteration: 16/16. Cls loss: 0.05188. Reg loss: 0.17253. Batch loss: 0.22441 Total loss: 0.17619</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 51/100. Iteration: 16/16. Cls loss: 0.05828. Reg loss: 0.15966. Batch loss: 0.21793 Total loss: 0.19821</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 52/100. Iteration: 16/16. Cls loss: 0.02468. Reg loss: 0.13103. Batch loss: 0.15571 Total loss: 0.17331</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.66it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 53/100. Iteration: 16/16. Cls loss: 0.05450. Reg loss: 0.15965. Batch loss: 0.21415 Total loss: 0.15721</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 54/100. Iteration: 16/16. Cls loss: 0.01389. Reg loss: 0.12303. Batch loss: 0.13692 Total loss: 0.16231</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.66it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 55/100. Iteration: 16/16. Cls loss: 0.01719. Reg loss: 0.10627. Batch loss: 0.12346 Total loss: 0.17559</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 56/100. Iteration: 16/16. Cls loss: 0.05516. Reg loss: 0.13558. Batch loss: 0.19074 Total loss: 0.16011</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 57/100. Iteration: 16/16. Cls loss: 0.01942. Reg loss: 0.11744. Batch loss: 0.13685 Total loss: 0.15328</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.66it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 58/100. Iteration: 16/16. Cls loss: 0.02838. Reg loss: 0.11467. Batch loss: 0.14305 Total loss: 0.15643</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 59/100. Iteration: 16/16. Cls loss: 0.01733. Reg loss: 0.14519. Batch loss: 0.16252 Total loss: 0.15355</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 60/100. Iteration: 16/16. Cls loss: 0.02179. Reg loss: 0.13774. Batch loss: 0.15954 Total loss: 0.15642</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.66it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 61/100. Iteration: 16/16. Cls loss: 0.02072. Reg loss: 0.10356. Batch loss: 0.12428 Total loss: 0.15226</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 62/100. Iteration: 16/16. Cls loss: 0.02937. Reg loss: 0.16516. Batch loss: 0.19453 Total loss: 0.15259</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.64it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 63/100. Iteration: 16/16. Cls loss: 0.01575. Reg loss: 0.11001. Batch loss: 0.12577 Total loss: 0.14444</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 64/100. Iteration: 16/16. Cls loss: 0.02118. Reg loss: 0.14723. Batch loss: 0.16841 Total loss: 0.14889</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 65/100. Iteration: 16/16. Cls loss: 0.01258. Reg loss: 0.10646. Batch loss: 0.11904 Total loss: 0.13811</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 66/100. Iteration: 16/16. Cls loss: 0.02637. Reg loss: 0.11956. Batch loss: 0.14593 Total loss: 0.14341</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 67/100. Iteration: 16/16. Cls loss: 0.02228. Reg loss: 0.11278. Batch loss: 0.13506 Total loss: 0.13103</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.64it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 68/100. Iteration: 16/16. Cls loss: 0.02174. Reg loss: 0.14281. Batch loss: 0.16455 Total loss: 0.14236</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.66it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 69/100. Iteration: 16/16. Cls loss: 0.02257. Reg loss: 0.12598. Batch loss: 0.14856 Total loss: 0.12524</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 70/100. Iteration: 16/16. Cls loss: 0.01217. Reg loss: 0.11650. Batch loss: 0.12868 Total loss: 0.12119</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 71/100. Iteration: 16/16. Cls loss: 0.02158. Reg loss: 0.11656. Batch loss: 0.13814 Total loss: 0.12942</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 72/100. Iteration: 16/16. Cls loss: 0.02688. Reg loss: 0.12128. Batch loss: 0.14816 Total loss: 0.12248</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.68it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 73/100. Iteration: 16/16. Cls loss: 0.03828. Reg loss: 0.13906. Batch loss: 0.17734 Total loss: 0.12962</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 74/100. Iteration: 16/16. Cls loss: 0.01571. Reg loss: 0.09172. Batch loss: 0.10742 Total loss: 0.11650</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 75/100. Iteration: 16/16. Cls loss: 0.00723. Reg loss: 0.07205. Batch loss: 0.07927 Total loss: 0.11073</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.66it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 76/100. Iteration: 16/16. Cls loss: 0.01137. Reg loss: 0.10261. Batch loss: 0.11397 Total loss: 0.11736</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 77/100. Iteration: 16/16. Cls loss: 0.01105. Reg loss: 0.10029. Batch loss: 0.11134 Total loss: 0.12013</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.66it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 78/100. Iteration: 16/16. Cls loss: 0.01158. Reg loss: 0.07661. Batch loss: 0.08818 Total loss: 0.10467</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 79/100. Iteration: 16/16. Cls loss: 0.01272. Reg loss: 0.11950. Batch loss: 0.13222 Total loss: 0.11289</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.63it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 80/100. Iteration: 16/16. Cls loss: 0.01632. Reg loss: 0.11802. Batch loss: 0.13434 Total loss: 0.11069</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 81/100. Iteration: 16/16. Cls loss: 0.01698. Reg loss: 0.09205. Batch loss: 0.10903 Total loss: 0.11323</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 82/100. Iteration: 16/16. Cls loss: 0.01507. Reg loss: 0.09333. Batch loss: 0.10841 Total loss: 0.11162</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.64it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 83/100. Iteration: 16/16. Cls loss: 0.01764. Reg loss: 0.08254. Batch loss: 0.10018 Total loss: 0.10754</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.64it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 84/100. Iteration: 16/16. Cls loss: 0.01967. Reg loss: 0.09698. Batch loss: 0.11664 Total loss: 0.08879</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 85/100. Iteration: 16/16. Cls loss: 0.01693. Reg loss: 0.12156. Batch loss: 0.13848 Total loss: 0.09241</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 86/100. Iteration: 16/16. Cls loss: 0.00852. Reg loss: 0.05064. Batch loss: 0.05916 Total loss: 0.08881</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 87/100. Iteration: 16/16. Cls loss: 0.00844. Reg loss: 0.06226. Batch loss: 0.07070 Total loss: 0.08545</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.66it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 88/100. Iteration: 16/16. Cls loss: 0.00888. Reg loss: 0.07203. Batch loss: 0.08091 Total loss: 0.08717</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 89/100. Iteration: 16/16. Cls loss: 0.01001. Reg loss: 0.06043. Batch loss: 0.07045 Total loss: 0.08225</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.66it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 90/100. Iteration: 16/16. Cls loss: 0.01435. Reg loss: 0.08745. Batch loss: 0.10180 Total loss: 0.08436</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 91/100. Iteration: 16/16. Cls loss: 0.01257. Reg loss: 0.08097. Batch loss: 0.09354 Total loss: 0.08861</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.67it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 92/100. Iteration: 16/16. Cls loss: 0.01717. Reg loss: 0.08003. Batch loss: 0.09720 Total loss: 0.07921</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.66it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 93/100. Iteration: 16/16. Cls loss: 0.00936. Reg loss: 0.04904. Batch loss: 0.05839 Total loss: 0.08292</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.64it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 94/100. Iteration: 16/16. Cls loss: 0.02082. Reg loss: 0.13735. Batch loss: 0.15818 Total loss: 0.08828</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.65it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 95/100. Iteration: 16/16. Cls loss: 0.00802. Reg loss: 0.06241. Batch loss: 0.07043 Total loss: 0.07767</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.63it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 96/100. Iteration: 16/16. Cls loss: 0.00671. Reg loss: 0.05355. Batch loss: 0.06026 Total loss: 0.08409</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.64it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 97/100. Iteration: 16/16. Cls loss: 0.00846. Reg loss: 0.05337. Batch loss: 0.06183 Total loss: 0.08002</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.64it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 98/100. Iteration: 16/16. Cls loss: 0.00915. Reg loss: 0.09728. Batch loss: 0.10644 Total loss: 0.08200</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.64it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 99/100. Iteration: 16/16. Cls loss: 0.01366. Reg loss: 0.07073. Batch loss: 0.08439 Total loss: 0.08084</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.64it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch    99: reducing learning rate of group 0 to 1.0000e-06.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"display:flex;flex-direction:row;\"><span>Epoch: 100/100. Iteration: 16/16. Cls loss: 0.00806. Reg loss: 0.04589. Batch loss: 0.05395 Total loss: 0.07791</span><progress style='margin:2px 4px;description_width:initial;' max='16' value='16'></progress>100% 16/16 [00:07&lt;00:00,  2.66it/s]</div>"
            ],
            "text/plain": [
              "<tqdm._fake_ipywidgets.HBox object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 19min 41s, sys: 2min 46s, total: 22min 28s\n",
            "Wall time: 24min 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS0pKdfd_Qjl"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_i_WH1V_s5F"
      },
      "source": [
        "COCO_CLASSES = [\"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\r\n",
        "                \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\",\r\n",
        "                \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\r\n",
        "                \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\",\r\n",
        "                \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\",\r\n",
        "                \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\",\r\n",
        "                \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\",\r\n",
        "                \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\r\n",
        "                \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\r\n",
        "                \"teddy bear\", \"hair drier\", \"toothbrush\"]\r\n",
        "\r\n",
        "colors = [(39, 129, 113), (164, 80, 133), (83, 122, 114), (99, 81, 172), (95, 56, 104), (37, 84, 86), (14, 89, 122),\r\n",
        "          (80, 7, 65), (10, 102, 25), (90, 185, 109), (106, 110, 132), (169, 158, 85), (188, 185, 26), (103, 1, 17),\r\n",
        "          (82, 144, 81), (92, 7, 184), (49, 81, 155), (179, 177, 69), (93, 187, 158), (13, 39, 73), (12, 50, 60),\r\n",
        "          (16, 179, 33), (112, 69, 165), (15, 139, 63), (33, 191, 159), (182, 173, 32), (34, 113, 133), (90, 135, 34),\r\n",
        "          (53, 34, 86), (141, 35, 190), (6, 171, 8), (118, 76, 112), (89, 60, 55), (15, 54, 88), (112, 75, 181),\r\n",
        "          (42, 147, 38), (138, 52, 63), (128, 65, 149), (106, 103, 24), (168, 33, 45), (28, 136, 135), (86, 91, 108),\r\n",
        "          (52, 11, 76), (142, 6, 189), (57, 81, 168), (55, 19, 148), (182, 101, 89), (44, 65, 179), (1, 33, 26),\r\n",
        "          (122, 164, 26), (70, 63, 134), (137, 106, 82), (120, 118, 52), (129, 74, 42), (182, 147, 112), (22, 157, 50),\r\n",
        "          (56, 50, 20), (2, 22, 177), (156, 100, 106), (21, 35, 42), (13, 8, 121), (142, 92, 28), (45, 118, 33),\r\n",
        "          (105, 118, 30), (7, 185, 124), (46, 34, 146), (105, 184, 169), (22, 18, 5), (147, 71, 73), (181, 64, 91),\r\n",
        "          (31, 39, 184), (164, 179, 33), (96, 50, 18), (95, 15, 106), (113, 68, 54), (136, 116, 112), (119, 139, 130),\r\n",
        "          (31, 139, 34), (66, 6, 127), (62, 39, 2), (49, 99, 180), (49, 119, 155), (153, 50, 183), (125, 38, 3),\r\n",
        "          (129, 87, 143), (49, 87, 40), (128, 62, 120), (73, 85, 148), (28, 144, 118), (29, 9, 24), (175, 45, 108),\r\n",
        "          (81, 175, 64), (178, 19, 157), (74, 188, 190), (18, 114, 2), (62, 128, 96), (21, 3, 150), (0, 6, 95),\r\n",
        "          (2, 20, 184), (122, 37, 185)]\r\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22M37JrN_XO4"
      },
      "source": [
        "import os\r\n",
        "import argparse\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torchvision import transforms\r\n",
        "from tensorboardX import SummaryWriter\r\n",
        "import shutil\r\n",
        "import numpy as np\r\n",
        "from tqdm.autonotebook import tqdm\r\n",
        "import cv2\r\n",
        "import time as time\r\n",
        "\r\n",
        "class Infer():\r\n",
        "    def __init__(self, verbose=1):\r\n",
        "        self.system_dict = {};\r\n",
        "        self.system_dict[\"verbose\"] = verbose;\r\n",
        "        self.system_dict[\"local\"] = {};\r\n",
        "        self.system_dict[\"local\"][\"common_size\"] = 512;\r\n",
        "        self.system_dict[\"local\"][\"mean\"] = np.array([[[0.485, 0.456, 0.406]]])\r\n",
        "        self.system_dict[\"local\"][\"std\"] = np.array([[[0.229, 0.224, 0.225]]])\r\n",
        "\r\n",
        "    def Model(self, model_dir=\"trained/\"):\r\n",
        "        self.system_dict[\"local\"][\"model\"] = torch.load(model_dir + \"/signatrix_efficientdet_coco.pth\").module\r\n",
        "        if torch.cuda.is_available():\r\n",
        "            self.system_dict[\"local\"][\"model\"] = self.system_dict[\"local\"][\"model\"].cuda();\r\n",
        "\r\n",
        "    def Predict(self, img_path, class_list, vis_threshold = 0.4,output_folder = 'Inference'):\r\n",
        "\r\n",
        "        if not os.path.exists(output_folder):\r\n",
        "            os.makedirs(output_folder)\r\n",
        "        \r\n",
        "        image_filename = os.path.basename(img_path)\r\n",
        "        img = cv2.imread(img_path);\r\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB);\r\n",
        "        image = img.astype(np.float32) / 255.;\r\n",
        "        image = (image.astype(np.float32) - self.system_dict[\"local\"][\"mean\"]) / self.system_dict[\"local\"][\"std\"]\r\n",
        "        height, width, _ = image.shape\r\n",
        "        if height > width:\r\n",
        "            scale = self.system_dict[\"local\"][\"common_size\"] / height\r\n",
        "            resized_height = self.system_dict[\"local\"][\"common_size\"]\r\n",
        "            resized_width = int(width * scale)\r\n",
        "        else:\r\n",
        "            scale = self.system_dict[\"local\"][\"common_size\"] / width\r\n",
        "            resized_height = int(height * scale)\r\n",
        "            resized_width = self.system_dict[\"local\"][\"common_size\"]\r\n",
        "\r\n",
        "        image = cv2.resize(image, (resized_width, resized_height))\r\n",
        "\r\n",
        "        new_image = np.zeros((self.system_dict[\"local\"][\"common_size\"], self.system_dict[\"local\"][\"common_size\"], 3))\r\n",
        "        new_image[0:resized_height, 0:resized_width] = image\r\n",
        "\r\n",
        "        img = torch.from_numpy(new_image)\r\n",
        "        \r\n",
        "        t0 = time.time()\r\n",
        "        with torch.no_grad():\r\n",
        "            if torch.cuda.is_available():\r\n",
        "                scores, labels, boxes = self.system_dict[\"local\"][\"model\"](img.cuda().permute(2, 0, 1).float().unsqueeze(dim=0))\r\n",
        "            else:\r\n",
        "                scores, labels, boxes = self.system_dict[\"local\"][\"model\"](img.permute(2, 0, 1).float().unsqueeze(dim=0))              \r\n",
        "            boxes /= scale;\r\n",
        "        duration = time.time() - t0\r\n",
        "        print('Done. (%.3fs)' % (time.time() - t0))\r\n",
        "\r\n",
        "\r\n",
        "        try:\r\n",
        "            if boxes.shape[0] > 0:\r\n",
        "                output_image = cv2.imread(img_path)\r\n",
        "\r\n",
        "                for box_id in range(boxes.shape[0]):\r\n",
        "                    pred_prob = float(scores[box_id])\r\n",
        "                    if pred_prob < vis_threshold:\r\n",
        "                        break\r\n",
        "                    pred_label = int(labels[box_id])\r\n",
        "                    xmin, ymin, xmax, ymax = boxes[box_id, :]\r\n",
        "                    color = colors[pred_label]\r\n",
        "                    cv2.rectangle(output_image, (xmin, ymin), (xmax, ymax), color, 2)\r\n",
        "                    text_size = cv2.getTextSize(class_list[pred_label] + ' : %.2f' % pred_prob, cv2.FONT_HERSHEY_PLAIN, 1, 1)[0]\r\n",
        "\r\n",
        "                    cv2.rectangle(output_image, (xmin, ymin), (xmin + text_size[0] + 3, ymin + text_size[1] + 4), color, -1)\r\n",
        "                    cv2.putText(\r\n",
        "                        output_image, class_list[pred_label] + ' : %.2f' % pred_prob,\r\n",
        "                        (xmin, ymin + text_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1,\r\n",
        "                        (255, 255, 255), 1)\r\n",
        "\r\n",
        "            #cv2.imwrite(os.path.join(output_folder, image_filename), output_image)\r\n",
        "            #cv2.imwrite(\"output.jpg\", output_image)\r\n",
        "            return duration, scores, labels, boxes\r\n",
        "        \r\n",
        "        except:\r\n",
        "            print(\"NO Object Detected\")\r\n",
        "            return None\r\n",
        "\r\n",
        "    def predict_batch_of_images(self, img_folder, class_list, vis_threshold = 0.4, output_folder='Inference'):\r\n",
        "        \r\n",
        "        all_filenames = os.listdir(img_folder)\r\n",
        "        all_filenames.sort()\r\n",
        "        generated_count = 0\r\n",
        "        for filename in all_filenames:\r\n",
        "            img_path = \"{}/{}\".format(img_folder, filename)\r\n",
        "            try:\r\n",
        "                self.Predict(img_path , class_list, vis_threshold ,output_folder)\r\n",
        "                generated_count += 1\r\n",
        "            except:\r\n",
        "                continue\r\n",
        "        print(\"Objects detected  for {} images\".format(generated_count))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YL6ttyUMAH0x"
      },
      "source": [
        "gtf = Infer()\r\n",
        "gtf.Model(model_dir=\"trained_weight/\")\r\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foy8ObZrANZ3",
        "outputId": "3b757cc5-0693-4a2d-816c-e2e29fbc49eb"
      },
      "source": [
        "#extract class list from our annotations\r\n",
        "import json\r\n",
        "with open('space/train/_annotations.coco.json') as json_file:\r\n",
        "    data = json.load(json_file)\r\n",
        "class_list = []\r\n",
        "for category in data['categories']:\r\n",
        "  class_list.append(category['name'])\r\n",
        "\r\n",
        "class_list"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A', 'Astroid', 'Space_craft']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97mjPLMMANdP",
        "outputId": "033b28c1-62a5-4721-ad71-387579f301a2"
      },
      "source": [
        "test_images = [f for f in os.listdir('space/test') if f.endswith('.jpg')]\r\n",
        "import random\r\n",
        "img_path = \"space/test/\" + random.choice(test_images);\r\n",
        "duration, scores, labels, boxes = gtf.Predict(img_path, class_list, vis_threshold=0.2)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done. (0.033s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk2-nJh1ZjNt"
      },
      "source": [
        "pred = {}\r\n",
        "pred['boxes'] = boxes\r\n",
        "pred['scores'] = scores\r\n",
        "pred['labels'] = labels"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiLEi4OVZRQ0"
      },
      "source": [
        "import torchvision\r\n",
        "\r\n",
        "def apply_nms(orig_prediction, iou_thresh=0.3):\r\n",
        "    \r\n",
        "    # torchvision returns the indices of the bboxes to keep\r\n",
        "    keep = torchvision.ops.nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)\r\n",
        "    \r\n",
        "    final_prediction = orig_prediction\r\n",
        "    final_prediction['boxes'] = final_prediction['boxes'][keep]\r\n",
        "    final_prediction['scores'] = final_prediction['scores'][keep]\r\n",
        "    final_prediction['labels'] = final_prediction['labels'][keep]\r\n",
        "    \r\n",
        "    return final_prediction\r\n",
        "\r\n",
        "pred = apply_nms(pred, iou_thresh=0.01)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "gXjHVR7TYsAX",
        "outputId": "097a189c-c45d-4138-a873-1617f7aa4bd3"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.patches as patches\r\n",
        "plt.rcParams['text.color'] = 'white'\r\n",
        "img = cv2.imread(img_path)\r\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
        "\r\n",
        "fig, a = plt.subplots(1,1)\r\n",
        "fig.set_size_inches(5,5)\r\n",
        "a.imshow(img)\r\n",
        "for (box, label, score) in zip(pred['boxes'], pred['labels'], pred['scores']):\r\n",
        "    x, y, width, height  = box[0], box[1], box[2]-box[0], box[3]-box[1]\r\n",
        "    rect = patches.Rectangle((x, y),\r\n",
        "                                width, height,\r\n",
        "                                linewidth = 1,\r\n",
        "                                edgecolor = 'g',\r\n",
        "                                facecolor = 'none')\r\n",
        "\r\n",
        "    s = class_list[label.cpu().numpy()] + ' ({})'.format(score.item())\r\n",
        "    print(s)\r\n",
        "    a.text(x-5, y-5, s)\r\n",
        "\r\n",
        "    # Draw the bounding box on top of the image\r\n",
        "    a.add_patch(rect)\r\n",
        "plt.show()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Space_craft (0.9974149465560913)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}